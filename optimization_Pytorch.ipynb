{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T08:07:54.362920Z",
     "start_time": "2019-07-26T08:07:52.836709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorboardX in /Users/raj/anaconda3/lib/python3.7/site-packages (1.8)\r\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/raj/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.12.0)\r\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.2.0 in /Users/raj/anaconda3/lib/python3.7/site-packages (from tensorboardX) (3.9.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/raj/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.16.2)\r\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/raj/anaconda3/lib/python3.7/site-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "cmd = \"pip install --upgrade tensorboardX --user \"\n",
    "pw = \"data\"\n",
    "!echo {pw}|  {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T08:08:32.328619Z",
     "start_time": "2019-07-26T08:08:32.160879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accessing predefined path\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "log_path = './runs/gd/'\n",
    "\n",
    "if log_path:\n",
    "    print(\"accessing predefined path\")\n",
    "    writer = SummaryWriter(log_dir=log_path)\n",
    "else :\n",
    "    print(\"using new path set\")\n",
    "    writer = SummaryWriter(log_dir='./runs/gd/')\n",
    "#In addition to SummaryWriter, there are also other writers, please check the manual\n",
    "# https://tensorboardx.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# !tensorboard --logdir log_path --host localhost --port 8088\n",
    "# you have to execute tensorboard command from another shell, otherwise you cannot proceed with running the notebook\n",
    "# read this : https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T08:08:51.932256Z",
     "start_time": "2019-07-26T08:08:51.583187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6225, 0.3694, 0.1113,  ..., 0.6998, 0.4621, 0.9274],\n",
      "        [0.4345, 0.1057, 0.7422,  ..., 0.6136, 0.4320, 0.2926],\n",
      "        [0.0261, 0.4799, 0.1402,  ..., 0.3361, 0.7007, 0.3955],\n",
      "        ...,\n",
      "        [0.2035, 0.7750, 0.1440,  ..., 0.1190, 0.0940, 0.0635],\n",
      "        [0.1793, 0.3373, 0.0920,  ..., 0.5139, 0.5928, 0.5492],\n",
      "        [0.8085, 0.4528, 0.8492,  ..., 0.9411, 0.1687, 0.8990]]) tensor([[0.8645, 0.5277, 0.3037,  ..., 0.2723, 0.3645, 0.6205],\n",
      "        [0.7345, 0.4696, 0.3540,  ..., 0.1247, 0.1751, 0.7457],\n",
      "        [0.9690, 0.1013, 0.5195,  ..., 0.3983, 0.4856, 0.2331],\n",
      "        ...,\n",
      "        [0.3596, 0.4700, 0.8591,  ..., 0.1756, 0.7961, 0.9431],\n",
      "        [0.8931, 0.2892, 0.7706,  ..., 0.2964, 0.1916, 0.8530],\n",
      "        [0.4916, 0.4282, 0.1869,  ..., 0.8776, 0.1562, 0.3275]])\n",
      "something 0 3415983.5\n",
      "something 1 3415983.5\n",
      "something 2 3415983.5\n",
      "something 3 3415983.5\n",
      "something 4 3415983.5\n",
      "something 5 3415983.5\n",
      "something 6 3415983.5\n",
      "something 7 3415983.5\n",
      "something 8 3415983.5\n",
      "something 9 3415983.5\n",
      "something 10 3415983.5\n",
      "something 11 3415983.5\n",
      "something 12 3415983.5\n",
      "something 13 3415983.5\n",
      "something 14 3415983.5\n",
      "something 15 3415983.5\n",
      "something 16 3415983.5\n",
      "something 17 3415983.5\n",
      "something 18 3415983.5\n",
      "something 19 3415983.5\n",
      "something 20 3415983.5\n",
      "something 21 3415983.5\n",
      "something 22 3415983.5\n",
      "something 23 3415983.5\n",
      "something 24 3415983.5\n",
      "something 25 3415983.5\n",
      "something 26 3415983.5\n",
      "something 27 3415983.5\n",
      "something 28 3415983.5\n",
      "something 29 3415983.5\n",
      "something 30 3415983.5\n",
      "something 31 3415983.5\n",
      "something 32 3415983.5\n",
      "something 33 3415983.5\n",
      "something 34 3415983.5\n",
      "something 35 3415983.5\n",
      "something 36 3415983.5\n",
      "something 37 3415983.5\n",
      "something 38 3415983.5\n",
      "something 39 3415983.5\n",
      "something 40 3415983.5\n",
      "something 41 3415983.5\n",
      "something 42 3415983.5\n",
      "something 43 3415983.5\n",
      "something 44 3415983.5\n",
      "something 45 3415983.5\n",
      "something 46 3415983.5\n",
      "something 47 3415983.5\n",
      "something 48 3415983.5\n",
      "something 49 3415983.5\n",
      "something 50 3415983.5\n",
      "something 51 3415983.5\n",
      "something 52 3415983.5\n",
      "something 53 3415983.5\n",
      "something 54 3415983.5\n",
      "something 55 3415983.5\n",
      "something 56 3415983.5\n",
      "something 57 3415983.5\n",
      "something 58 3415983.5\n",
      "something 59 3415983.5\n",
      "something 60 3415983.5\n",
      "something 61 3415983.5\n",
      "something 62 3415983.5\n",
      "something 63 3415983.5\n",
      "something 64 3415983.5\n",
      "something 65 3415983.5\n",
      "something 66 3415983.5\n",
      "something 67 3415983.5\n",
      "something 68 3415983.5\n",
      "something 69 3415983.5\n",
      "something 70 3415983.5\n",
      "something 71 3415983.5\n",
      "something 72 3415983.5\n",
      "something 73 3415983.5\n",
      "something 74 3415983.5\n",
      "something 75 3415983.5\n",
      "something 76 3415983.5\n",
      "something 77 3415983.5\n",
      "something 78 3415983.5\n",
      "something 79 3415983.5\n",
      "something 80 3415983.5\n",
      "something 81 3415983.5\n",
      "something 82 3415983.5\n",
      "something 83 3415983.5\n",
      "something 84 3415983.5\n",
      "something 85 3415983.5\n",
      "something 86 3415983.5\n",
      "something 87 3415983.5\n",
      "something 88 3415983.5\n",
      "something 89 3415983.5\n",
      "something 90 3415983.5\n",
      "something 91 3415983.5\n",
      "something 92 3415983.5\n",
      "something 93 3415983.5\n",
      "something 94 3415983.5\n",
      "something 95 3415983.5\n",
      "something 96 3415983.5\n",
      "something 97 3415983.5\n",
      "something 98 3415983.5\n",
      "something 99 3415983.5\n",
      "something 100 3415983.5\n",
      "something 101 3415983.5\n",
      "something 102 3415983.5\n",
      "something 103 3415983.5\n",
      "something 104 3415983.5\n",
      "something 105 3415983.5\n",
      "something 106 3415983.5\n",
      "something 107 3415983.5\n",
      "something 108 3415983.5\n",
      "something 109 3415983.5\n",
      "something 110 3415983.5\n",
      "something 111 3415983.5\n",
      "something 112 3415983.5\n",
      "something 113 3415983.5\n",
      "something 114 3415983.5\n",
      "something 115 3415983.5\n",
      "something 116 3415983.5\n",
      "something 117 3415983.5\n",
      "something 118 3415983.5\n",
      "something 119 3415983.5\n",
      "something 120 3415983.5\n",
      "something 121 3415983.5\n",
      "something 122 3415983.5\n",
      "something 123 3415983.5\n",
      "something 124 3415983.5\n",
      "something 125 3415983.5\n",
      "something 126 3415983.5\n",
      "something 127 3415983.5\n",
      "something 128 3415983.5\n",
      "something 129 3415983.5\n",
      "something 130 3415983.5\n",
      "something 131 3415983.5\n",
      "something 132 3415983.5\n",
      "something 133 3415983.5\n",
      "something 134 3415983.5\n",
      "something 135 3415983.5\n",
      "something 136 3415983.5\n",
      "something 137 3415983.5\n",
      "something 138 3415983.5\n",
      "something 139 3415983.5\n",
      "something 140 3415983.5\n",
      "something 141 3415983.5\n",
      "something 142 3415983.5\n",
      "something 143 3415983.5\n",
      "something 144 3415983.5\n",
      "something 145 3415983.5\n",
      "something 146 3415983.5\n",
      "something 147 3415983.5\n",
      "something 148 3415983.5\n",
      "something 149 3415983.5\n",
      "something 150 3415983.5\n",
      "something 151 3415983.5\n",
      "something 152 3415983.5\n",
      "something 153 3415983.5\n",
      "something 154 3415983.5\n",
      "something 155 3415983.5\n",
      "something 156 3415983.5\n",
      "something 157 3415983.5\n",
      "something 158 3415983.5\n",
      "something 159 3415983.5\n",
      "something 160 3415983.5\n",
      "something 161 3415983.5\n",
      "something 162 3415983.5\n",
      "something 163 3415983.5\n",
      "something 164 3415983.5\n",
      "something 165 3415983.5\n",
      "something 166 3415983.5\n",
      "something 167 3415983.5\n",
      "something 168 3415983.5\n",
      "something 169 3415983.5\n",
      "something 170 3415983.5\n",
      "something 171 3415983.5\n",
      "something 172 3415983.5\n",
      "something 173 3415983.5\n",
      "something 174 3415983.5\n",
      "something 175 3415983.5\n",
      "something 176 3415983.5\n",
      "something 177 3415983.5\n",
      "something 178 3415983.5\n",
      "something 179 3415983.5\n",
      "something 180 3415983.5\n",
      "something 181 3415983.5\n",
      "something 182 3415983.5\n",
      "something 183 3415983.5\n",
      "something 184 3415983.5\n",
      "something 185 3415983.5\n",
      "something 186 3415983.5\n",
      "something 187 3415983.5\n",
      "something 188 3415983.5\n",
      "something 189 3415983.5\n",
      "something 190 3415983.5\n",
      "something 191 3415983.5\n",
      "something 192 3415983.5\n",
      "something 193 3415983.5\n",
      "something 194 3415983.5\n",
      "something 195 3415983.5\n",
      "something 196 3415983.5\n",
      "something 197 3415983.5\n",
      "something 198 3415983.5\n",
      "something 199 3415983.5\n",
      "something 200 3415983.5\n",
      "something 201 3415983.5\n",
      "something 202 3415983.5\n",
      "something 203 3415983.5\n",
      "something 204 3415983.5\n",
      "something 205 3415983.5\n",
      "something 206 3415983.5\n",
      "something 207 3415983.5\n",
      "something 208 3415983.5\n",
      "something 209 3415983.5\n",
      "something 210 3415983.5\n",
      "something 211 3415983.5\n",
      "something 212 3415983.5\n",
      "something 213 3415983.5\n",
      "something 214 3415983.5\n",
      "something 215 3415983.5\n",
      "something 216 3415983.5\n",
      "something 217 3415983.5\n",
      "something 218 3415983.5\n",
      "something 219 3415983.5\n",
      "something 220 3415983.5\n",
      "something 221 3415983.5\n",
      "something 222 3415983.5\n",
      "something 223 3415983.5\n",
      "something 224 3415983.5\n",
      "something 225 3415983.5\n",
      "something 226 3415983.5\n",
      "something 227 3415983.5\n",
      "something 228 3415983.5\n",
      "something 229 3415983.5\n",
      "something 230 3415983.5\n",
      "something 231 3415983.5\n",
      "something 232 3415983.5\n",
      "something 233 3415983.5\n",
      "something 234 3415983.5\n",
      "something 235 3415983.5\n",
      "something 236 3415983.5\n",
      "something 237 3415983.5\n",
      "something 238 3415983.5\n",
      "something 239 3415983.5\n",
      "something 240 3415983.5\n",
      "something 241 3415983.5\n",
      "something 242 3415983.5\n",
      "something 243 3415983.5\n",
      "something 244 3415983.5\n",
      "something 245 3415983.5\n",
      "something 246 3415983.5\n",
      "something 247 3415983.5\n",
      "something 248 3415983.5\n",
      "something 249 3415983.5\n",
      "something 250 3415983.5\n",
      "something 251 3415983.5\n",
      "something 252 3415983.5\n",
      "something 253 3415983.5\n",
      "something 254 3415983.5\n",
      "something 255 3415983.5\n",
      "something 256 3415983.5\n",
      "something 257 3415983.5\n",
      "something 258 3415983.5\n",
      "something 259 3415983.5\n",
      "something 260 3415983.5\n",
      "something 261 3415983.5\n",
      "something 262 3415983.5\n",
      "something 263 3415983.5\n",
      "something 264 3415983.5\n",
      "something 265 3415983.5\n",
      "something 266 3415983.5\n",
      "something 267 3415983.5\n",
      "something 268 3415983.5\n",
      "something 269 3415983.5\n",
      "something 270 3415983.5\n",
      "something 271 3415983.5\n",
      "something 272 3415983.5\n",
      "something 273 3415983.5\n",
      "something 274 3415983.5\n",
      "something 275 3415983.5\n",
      "something 276 3415983.5\n",
      "something 277 3415983.5\n",
      "something 278 3415983.5\n",
      "something 279 3415983.5\n",
      "something 280 3415983.5\n",
      "something 281 3415983.5\n",
      "something 282 3415983.5\n",
      "something 283 3415983.5\n",
      "something 284 3415983.5\n",
      "something 285 3415983.5\n",
      "something 286 3415983.5\n",
      "something 287 3415983.5\n",
      "something 288 3415983.5\n",
      "something 289 3415983.5\n",
      "something 290 3415983.5\n",
      "something 291 3415983.5\n",
      "something 292 3415983.5\n",
      "something 293 3415983.5\n",
      "something 294 3415983.5\n",
      "something 295 3415983.5\n",
      "something 296 3415983.5\n",
      "something 297 3415983.5\n",
      "something 298 3415983.5\n",
      "something 299 3415983.5\n",
      "something 300 3415983.5\n",
      "something 301 3415983.5\n",
      "something 302 3415983.5\n",
      "something 303 3415983.5\n",
      "something 304 3415983.5\n",
      "something 305 3415983.5\n",
      "something 306 3415983.5\n",
      "something 307 3415983.5\n",
      "something 308 3415983.5\n",
      "something 309 3415983.5\n",
      "something 310 3415983.5\n",
      "something 311 3415983.5\n",
      "something 312 3415983.5\n",
      "something 313 3415983.5\n",
      "something 314 3415983.5\n",
      "something 315 3415983.5\n",
      "something 316 3415983.5\n",
      "something 317 3415983.5\n",
      "something 318 3415983.5\n",
      "something 319 3415983.5\n",
      "something 320 3415983.5\n",
      "something 321 3415983.5\n",
      "something 322 3415983.5\n",
      "something 323 3415983.5\n",
      "something 324 3415983.5\n",
      "something 325 3415983.5\n",
      "something 326 3415983.5\n",
      "something 327 3415983.5\n",
      "something 328 3415983.5\n",
      "something 329 3415983.5\n",
      "something 330 3415983.5\n",
      "something 331 3415983.5\n",
      "something 332 3415983.5\n",
      "something 333 3415983.5\n",
      "something 334 3415983.5\n",
      "something 335 3415983.5\n",
      "something 336 3415983.5\n",
      "something 337 3415983.5\n",
      "something 338 3415983.5\n",
      "something 339 3415983.5\n",
      "something 340 3415983.5\n",
      "something 341 3415983.5\n",
      "something 342 3415983.5\n",
      "something 343 3415983.5\n",
      "something 344 3415983.5\n",
      "something 345 3415983.5\n",
      "something 346 3415983.5\n",
      "something 347 3415983.5\n",
      "something 348 3415983.5\n",
      "something 349 3415983.5\n",
      "something 350 3415983.5\n",
      "something 351 3415983.5\n",
      "something 352 3415983.5\n",
      "something 353 3415983.5\n",
      "something 354 3415983.5\n",
      "something 355 3415983.5\n",
      "something 356 3415983.5\n",
      "something 357 3415983.5\n",
      "something 358 3415983.5\n",
      "something 359 3415983.5\n",
      "something 360 3415983.5\n",
      "something 361 3415983.5\n",
      "something 362 3415983.5\n",
      "something 363 3415983.5\n",
      "something 364 3415983.5\n",
      "something 365 3415983.5\n",
      "something 366 3415983.5\n",
      "something 367 3415983.5\n",
      "something 368 3415983.5\n",
      "something 369 3415983.5\n",
      "something 370 3415983.5\n",
      "something 371 3415983.5\n",
      "something 372 3415983.5\n",
      "something 373 3415983.5\n",
      "something 374 3415983.5\n",
      "something 375 3415983.5\n",
      "something 376 3415983.5\n",
      "something 377 3415983.5\n",
      "something 378 3415983.5\n",
      "something 379 3415983.5\n",
      "something 380 3415983.5\n",
      "something 381 3415983.5\n",
      "something 382 3415983.5\n",
      "something 383 3415983.5\n",
      "something 384 3415983.5\n",
      "something 385 3415983.5\n",
      "something 386 3415983.5\n",
      "something 387 3415983.5\n",
      "something 388 3415983.5\n",
      "something 389 3415983.5\n",
      "something 390 3415983.5\n",
      "something 391 3415983.5\n",
      "something 392 3415983.5\n",
      "something 393 3415983.5\n",
      "something 394 3415983.5\n",
      "something 395 3415983.5\n",
      "something 396 3415983.5\n",
      "something 397 3415983.5\n",
      "something 398 3415983.5\n",
      "something 399 3415983.5\n",
      "something 400 3415983.5\n",
      "something 401 3415983.5\n",
      "something 402 3415983.5\n",
      "something 403 3415983.5\n",
      "something 404 3415983.5\n",
      "something 405 3415983.5\n",
      "something 406 3415983.5\n",
      "something 407 3415983.5\n",
      "something 408 3415983.5\n",
      "something 409 3415983.5\n",
      "something 410 3415983.5\n",
      "something 411 3415983.5\n",
      "something 412 3415983.5\n",
      "something 413 3415983.5\n",
      "something 414 3415983.5\n",
      "something 415 3415983.5\n",
      "something 416 3415983.5\n",
      "something 417 3415983.5\n",
      "something 418 3415983.5\n",
      "something 419 3415983.5\n",
      "something 420 3415983.5\n",
      "something 421 3415983.5\n",
      "something 422 3415983.5\n",
      "something 423 3415983.5\n",
      "something 424 3415983.5\n",
      "something 425 3415983.5\n",
      "something 426 3415983.5\n",
      "something 427 3415983.5\n",
      "something 428 3415983.5\n",
      "something 429 3415983.5\n",
      "something 430 3415983.5\n",
      "something 431 3415983.5\n",
      "something 432 3415983.5\n",
      "something 433 3415983.5\n",
      "something 434 3415983.5\n",
      "something 435 3415983.5\n",
      "something 436 3415983.5\n",
      "something 437 3415983.5\n",
      "something 438 3415983.5\n",
      "something 439 3415983.5\n",
      "something 440 3415983.5\n",
      "something 441 3415983.5\n",
      "something 442 3415983.5\n",
      "something 443 3415983.5\n",
      "something 444 3415983.5\n",
      "something 445 3415983.5\n",
      "something 446 3415983.5\n",
      "something 447 3415983.5\n",
      "something 448 3415983.5\n",
      "something 449 3415983.5\n",
      "something 450 3415983.5\n",
      "something 451 3415983.5\n",
      "something 452 3415983.5\n",
      "something 453 3415983.5\n",
      "something 454 3415983.5\n",
      "something 455 3415983.5\n",
      "something 456 3415983.5\n",
      "something 457 3415983.5\n",
      "something 458 3415983.5\n",
      "something 459 3415983.5\n",
      "something 460 3415983.5\n",
      "something 461 3415983.5\n",
      "something 462 3415983.5\n",
      "something 463 3415983.5\n",
      "something 464 3415983.5\n",
      "something 465 3415983.5\n",
      "something 466 3415983.5\n",
      "something 467 3415983.5\n",
      "something 468 3415983.5\n",
      "something 469 3415983.5\n",
      "something 470 3415983.5\n",
      "something 471 3415983.5\n",
      "something 472 3415983.5\n",
      "something 473 3415983.5\n",
      "something 474 3415983.5\n",
      "something 475 3415983.5\n",
      "something 476 3415983.5\n",
      "something 477 3415983.5\n",
      "something 478 3415983.5\n",
      "something 479 3415983.5\n",
      "something 480 3415983.5\n",
      "something 481 3415983.5\n",
      "something 482 3415983.5\n",
      "something 483 3415983.5\n",
      "something 484 3415983.5\n",
      "something 485 3415983.5\n",
      "something 486 3415983.5\n",
      "something 487 3415983.5\n",
      "something 488 3415983.5\n",
      "something 489 3415983.5\n",
      "something 490 3415983.5\n",
      "something 491 3415983.5\n",
      "something 492 3415983.5\n",
      "something 493 3415983.5\n",
      "something 494 3415983.5\n",
      "something 495 3415983.5\n",
      "something 496 3415983.5\n",
      "something 497 3415983.5\n",
      "something 498 3415983.5\n",
      "something 499 3415983.5\n"
     ]
    }
   ],
   "source": [
    "# Code in file autograd/two_layer_net_autograd.py\n",
    "import torch\n",
    "\n",
    "#device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "device = torch.device('cpu') # Uncomment this to run on CPU\n",
    "\n",
    "# N is batch size;\n",
    "# D_in is input dimension;\n",
    "# H is hidden dimension; \n",
    "#D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 20, 20, 20\n",
    "\n",
    "# input data : batch of 64 times 1000 features\n",
    "# output data : 100 x 10 continues values (real scalars)\n",
    "\n",
    "\n",
    "# Create random Tensors to hold input and outputs\n",
    "x = torch.rand(N, D_in, device=device) # generate normally distributed data of dim NxD_in, store it on device, requires_grad = False\n",
    "y = torch.rand(N, D_out, device=device) # generate normally distributed data of dim NxD_out, store it on device, requires_grad = False\n",
    "\n",
    "print (x, y)\n",
    "# Create random Tensors for weights; setting requires_grad=True means that we\n",
    "# want to compute gradients for these Tensors during the backward pass.\n",
    "# here the gradient will be computed for the variables that are related to the model learning something new,\n",
    "# i.e. the network weights in this case\n",
    "\n",
    "\n",
    "# WEIGHTS\n",
    "w1 = torch.rand(D_in, H, device=device, requires_grad=True) #generate normally distributed data of dim D_in x H, store it on device, requires_grad = True \n",
    "w2 = torch.rand(H, D_out, device=device, requires_grad=True)#generate normally distributed data of dim H x D_out, store it on device, requires_grad = True \n",
    "\n",
    "# initialize loss value to a high number \n",
    "\n",
    "# initialize arrays errors, w1_array and w2_array to empty lists\n",
    "errors = 1 # write here\n",
    "w1_array =  1 # write here\n",
    "w2_array =  1 # write here\n",
    " # set the network learning rate parameter 'learning_rate' to some small number\n",
    "learning_rate = 1e-20\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    loss = (y_pred -y).pow(2).sum()\n",
    "    print( t, loss.item())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w1.grad\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***a. What are the basic elements of optimization? Give some examples.***\n",
    "\n",
    "There are three basic elements for any optimization regardless the field from where the optimization problems come.\n",
    "\n",
    "1- Variables - free parameters which the algorithm, a set of functions, can run.\n",
    "\n",
    "2- Constraints - the boundaries for the variables in which the variables must fall.\n",
    "\n",
    "3- Objective function - the goal towards the algorithm drives the solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***b. Importance of Optimization in Machine Learning***\n",
    "\n",
    "Optimization is the key concept of machine learning. It helps the machine to reach and conculde the required tasks. it helps to use the data effectively and in estimating the computational load for a large data set processing, and to avoide local minima and search a good solution from a complex multi-dimensional space. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2.Recollect : What is a loss function / cost function? Give examples***\n",
    "\n",
    "Loss function / Cost function also called as error function. They indicate how far are we from the required output. There is no universal Loss function that works for all data.\n",
    "\n",
    "The small difference between Loss and Cost function is that Loss function is usually works on a data point, whereas cost function is more general. Cost function might be sum of loss functions over the training sed plus some model complexity.\n",
    "\n",
    "Usage area of loss function is mostly on parameter estimation whereas cost function is used in optimisation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***4. How is Hessian related to the gradient, eigenvalues, optimization and convergence?***\n",
    "\n",
    "Derivative - It measures the rate of changes of a function due to the changes between x and y variables.\n",
    "\n",
    "Gradient - is the rate of changes of some function (in deep learning, this is generally the loss function) in various directions. A gradient is simply a collection of the derivatives of the function for each direction. Each element of the gradient is simply the slope of the function in each direction.\n",
    "\n",
    "Hessian - is the derivative of the Gradient. Or we can say, it is the secondary derivative of the changing rate of slope.\n",
    "\n",
    "If the eigenvalues are larger then the Gradient is also larger. When the eigenvalues are larger then there is a larger curvature. The larger curvature with less optimization leads to faster convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
